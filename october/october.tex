\input{../header.tex}

\title{Work Log for October}
\author{Logan Brown}
%\date{} % Activate to display a given date or no date (if empty),
         % otherwise the current date is printed 


\begin{document}
\maketitle
\tableofcontents

\newpage


\section{Goals for the Month}
%Paste output from writeGoals
\begin{enumerate}
\item Find out what causes some of the probabilties to go outrageously high
\item Use the Simulated Yeast Genome, compare to the Ecoli genome
\item If possible, NSE Patch
\item Debugging Thoughts
\end{enumerate}

\section{Progress/Notes}

\subsection{Find out what causes some of the probabilties to go outrageously high}

\subsubsection{Compare Differences in the Code}
\begin{verbatim}
my.coef.r
my.drawPhiConditionalAllPred.r
my.drawPhiConditionalAll.r
my.estimatePhiOne.r
my.fitMultinomOne.r
my.logdmultinomCodOne.r
my.objectivePhiOne.Lfp.r
my.objectivePhiOne.nlogL.r
my.objectivePhiOne.nlogphiL.r
my.objectivePhiOne.phiLfp.r
my.pPropTypeNoObs.lognormal_bias.r
plotbin.r
plotmodel.r
simu.orf.r
\end{verbatim}


Codes where NSE and ROC are the same:
\begin{enumerate}
\item my.coef.r
\item my.estimatePhiOne.r

\end{enumerate}


\subsection{Look at stddev(phi)}

I have a run going that is tracking the scales of the MCMC for the phi values.

Since the scale of the MCMC should be about the Standard Devation of Phi, we'll see what happens.

PROBLEM:
The ROC model has different Phi scales for each gene. The NSE model keeps all the scales the same between different genes. That could be contributing to the problem? \sout{I think this is caused by the opatch we wrote that replaces Wei-Chen's scaling by .5  with subtracting out log(DBL\_MAX).}

\includegraphics[width=0.5\textwidth]{data/oct10-roc-scalehist.png}
\includegraphics[width=0.5\textwidth]{data/oct10-nse-scalehist.png}

\textbf{Every 6th time that the scale is updated, the code resets all the scales to 1. This definitely happens in Yeast (NSE and ROC), and it definitely happens for NSE (Yeast and Ecoli). Does it happen in ROC-Ecoli? Yes, confirmed.}

Also, Cedric says the number 6 is a result of the inputs. It has to do with the fact that my runs have been doing 50 samples between convergence checks and 10000 . I'm going to play with config.r to see this effect. (Confirmed).

Theory: length(.cubfitsEnv\$DrawScale\$phi) is $$\frac{\mbox{Number of Samples between Convergence Checks}}{100} + 1.$$

Every time that the code checks for convergence, it reinitializes some values, and causes the problem.

By changing my values in config.r so that the code never checks for convergence (and therefore, never resets the scale), we get the following picture (left, before teh change, right after the change)

\includegraphics[width=0.5\textwidth]{data/oct10-nse-scalehist.png}
\includegraphics[width=0.5\textwidth]{data/oct15-phiscales-after_change.png}

\begin{itemize}
\item It's worthy of note that this is the second time a run of the NSE model on the Yeast genome has run to completion. Since this has happened in the past, I don't want to entirely attribute the successful run to the removal of the scaling reset, but this is some evidence. This may have been the problem preventing a successful NSE run.

\item I expect the ROC model to have a similar but less dramatic change. The former phiscale values were all ones that were within $(1.2)^i(0.8)^j$ where $i, j, i+j \in \{0, 1,...,6\}$. The ROC model should have more varied scaling terms (likely a Normal distribution)

\item It appears that the "proper" distribution of the phi scales is roughly a normal distribution, that is slightly biased towards lower values. The whole set has mean=3.570621 and $\sigma$=1.196958.


\item but this seems odd to me. If the scale should be something like 4, but it was being artificially held back to $[0,2.48832]$, why was it therefore proposing NaN values? Shouldn't a LARGER scale make us more likely to propose impossible phi values? A small (and indeed, a very strangely behaving) scale should only prevent us from making progress, it shouldn't push us over some sort of cliff in the parameter space.
\end{itemize}


\subsection{Simulated Yeast Genome}

\subsubsection{Use Sections of the Simulated Yeast Genome}
I ran one 5th of the yeast genome(section1.fasta, section1.csv) and it FINISHED. but... not well.

See the results in data/10.01.yeastnse.*

\begin{itemize}
\item It took just over 30 hours to finish\\
started at: 2014-10-01 15:57:54\\
finished at: 2014-10-02 22:08:56 

\item The proposed phi values are still outrageously too high. The final proposed phi had mean value 2766786.09545948

\item Still proposing some 0 (-Inf) values for lpProp. At most, around 45-49 Inf per run.

\item Xobs (the original phi values) are generally much lower than the results of run

\item The values are not very accurate.

\end{itemize}


\subsubsection{Crashed Yeast Run}

The vast vast majority of the phi values being proposed are fine. -Inf values are throwing it off. 


\subsection{E. Coli genome}

A LARGE NSE RUN OF THE E. COLI GENOME RAN TO COMPLETION.



\subsection{If possible, NSE Patch}






\section{Goals for next Month}
\begin{enumerate}
\item Future Goal
\end{enumerate}


\end{document} %End of day document, REMOVE
